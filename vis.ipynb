{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchmetrics import MetricCollection, PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from torchmetrics import MetricCollection, PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleMinMax(x):\n",
    "\n",
    "    x = torch.stack([x[..., 0], x[..., 1], x[..., 2]], dim=-1)  # Select RGB channels\n",
    "\n",
    "    # Initialize an empty list to hold the scaled channels\n",
    "    scaled_channels = []\n",
    "    \n",
    "    # Iterate over each channel (assuming the input has shape [channels, height, width])\n",
    "    for c in range(x.shape[-1]):  # Iterate over channels\n",
    "        channel = x[..., c]\n",
    "        \n",
    "        # Min-max normalization for each channel separately\n",
    "        x_min = torch.min(channel)  # Minimum value for the channel\n",
    "        x_max = torch.max(channel)  # Maximum value for the channel\n",
    "        scaled_channel = (channel - x_min) / (x_max - x_min)\n",
    "        \n",
    "        # Add the scaled channel to the list\n",
    "        scaled_channels.append(scaled_channel)\n",
    "    \n",
    "    # Stack the scaled channels back together\n",
    "    scaled_image = torch.stack(scaled_channels, dim=-1)\n",
    "    return scaled_image\n",
    "\n",
    "device=\"cpu\"\n",
    "metric_collection = MetricCollection({\n",
    "        'psnr': PeakSignalNoiseRatio().to(device),\n",
    "        'ssim': StructuralSimilarityIndexMeasure().to(device)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(str(\"datasets/gf2/test_gf2_multiExm1.h5\"), 'r+')\n",
    "sr_init = torch.tensor(f['gt'][()], dtype=torch.float32).to(\"cpu\")[2]\n",
    "\n",
    "data = loadmat(f\"cannet/results/output_mulExm_{i}.mat\")['sr']\n",
    "img_init = torch.asarray(data).to(\"cpu\").permute(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "# Define the rectangle's position and size\n",
    "top_left = (13, 13)  # x, y position of top-left corner of the rectangle\n",
    "width, height = 20, 20  # Width and height of the rectangle\n",
    "bottom_right = (top_left[0] + width, top_left[1] + height)  # bottom-right corner of the rectangle (width=50, height=50)\n",
    "\n",
    "train_metric = metric_collection.forward(img_init.unsqueeze(0), sr_init.unsqueeze(0))\n",
    "large_metric = metric_collection.compute()\n",
    "metric_collection.reset()\n",
    "psnr_t = large_metric['psnr'].numpy()\n",
    "ssim_t = large_metric['ssim'].numpy()\n",
    "\n",
    "cropped_hr = img_init[:, top_left[1]:top_left[1]+height, top_left[0]:top_left[0]+width]\n",
    "cropped_sr = sr_init[:, top_left[1]:top_left[1]+height, top_left[0]:top_left[0]+width]\n",
    "train_metric = metric_collection.forward(cropped_hr.unsqueeze(0), cropped_sr.unsqueeze(0))\n",
    "cropped_large_metric = metric_collection.compute()\n",
    "metric_collection.reset()\n",
    "psnr_s = cropped_large_metric['psnr'].numpy()\n",
    "ssim_s = cropped_large_metric['ssim'].numpy()\n",
    "\n",
    "\n",
    "\n",
    "print(psnr_t, \"\", ssim_t)\n",
    "print(psnr_s, \"\", ssim_s)\n",
    "img_with_rectangle = img_init.clone()  # Make a copy of the image to modify\n",
    "\n",
    "\n",
    "\n",
    "sr_vis = scaleMinMax(sr_init.clone().permute(2, 1, 0)).numpy()\n",
    "sr_vis_rect = sr_vis.copy()\n",
    "\n",
    "cv2.rectangle(sr_vis_rect, top_left, bottom_right, (255, 0, 0), thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "cropped_sr = sr_vis[top_left[1]:top_left[1]+height, top_left[0]:top_left[0]+width]\n",
    "\n",
    "cropped_resized = cv2.resize(cropped_sr, \n",
    "                             (cropped_sr.shape[0] * 6, cropped_sr.shape[1] * 6))\n",
    "\n",
    "h, w = sr_vis.shape[0], sr_vis.shape[1]  # Image dimensions (height, width)\n",
    "h_resized, w_resized = cropped_resized.shape[:2]\n",
    "\n",
    "top_left_resized = (w - w_resized - 2, h - h_resized - 2)  # A little padding of 10 pixels\n",
    "\n",
    "\n",
    "sr_vis_rect[top_left_resized[1]:top_left_resized[1] + h_resized, \n",
    "                   top_left_resized[0]:top_left_resized[0] + w_resized] = cropped_resized\n",
    "\n",
    "cv2.rectangle(sr_vis_rect, \n",
    "              (top_left_resized[0] - 1, top_left_resized[1] - 1), \n",
    "              (top_left_resized[0] + w_resized + 1, top_left_resized[1] + h_resized + 1),\n",
    "              (0.50, 0.50, 0.50), thickness=2)  # Gray color and thickness=2\n",
    "\n",
    "text = f\"{psnr_s:.2f}/{ssim_s:.4f}\"\n",
    "\n",
    "# Use cv2.putText to add the text on the image\n",
    "font = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "font_scale = 0.42\n",
    "font_thickness = 1\n",
    "\n",
    "# Calculate text size and background rectangle size\n",
    "text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "text_width, text_height = text_size[0], text_size[1]\n",
    "\n",
    "# Position for the text relative to the bottom-right rectangle\n",
    "text_x = 145  # Align with the left edge of the bottom-right rectangle\n",
    "text_y = 132  # Slightly above the bottom-right rectangle\n",
    "text_width = 106\n",
    "text_height = 30\n",
    "\n",
    "text_x_ = 150\n",
    "text_y_ = 126\n",
    "\n",
    "# Draw a filled gray rectangle as the background for the text\n",
    "cv2.rectangle(sr_vis_rect,\n",
    "              (text_x, text_y - text_height),  # Top-left corner of the background rectangle\n",
    "              (text_x + text_width, text_y),  # Bottom-right corner of the background rectangle\n",
    "              (0.50, 0.50, 0.50),  # Gray color\n",
    "              thickness=-1)  # Filled rectangle\n",
    "\n",
    "# Overlay the text on the gray rectangle\n",
    "cv2.putText(sr_vis_rect, text, (text_x_, text_y_), font, font_scale, (0,0,0), font_thickness)\n",
    "\n",
    "title = f\"CanNet\\n{psnr_t:.2f}/{ssim_t:.4f}\"\n",
    "plt.title(title, fontsize=18)  # Add the title \"LagNet\"\n",
    "plt.imshow(sr_vis_rect)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_vis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Draw a rectangle with thickness = 2 (border only, empty inside)\n",
    "cv2.rectangle(img_with_rectangle, top_left, bottom_right, (255, 0, 0), thickness=1)\n",
    "\n",
    "cropped_img = img_with_rectangle[top_left[1]:top_left[1]+height, top_left[0]:top_left[0]+width]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img_with_rectangle)\n",
    "plt.axis('off')  # Remove the axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtering the data to only show values for channels 2, 4, 6, and 8\n",
    "channels = [2, 4, 6, 8]\n",
    "psnr_line1 = [40.523, 38.421, 37.104, 36.067]\n",
    "psnr_line2 = [40.242, 38.202, 37.401, 36.467]\n",
    "psnr_line3 = [39.834, 38.123, 37.524, 37.067]\n",
    "\n",
    "# Creating the plot with the filtered data\n",
    "plt.style.use('seaborn-v0_8-colorblind')  # Scientific style\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(channels, psnr_line1, marker='o', label=\"0\", color='blue', linestyle='-')\n",
    "plt.plot(channels, psnr_line2, marker='s', label=\"0.5\", color='green', linestyle='--')\n",
    "plt.plot(channels, psnr_line3, marker='^', label=\"1\", color='red', linestyle='-.')\n",
    "\n",
    "# Adding labels, title, legend, and grid\n",
    "plt.xlabel(\"Number of Spectral Channels\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"PSNR (dB)\", fontsize=14, labelpad=10)\n",
    "plt.legend(title=\"Conv Scale\", fontsize=12, title_fontsize=12, loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xticks(channels)\n",
    "\n",
    "# Adjusting the layout for better presentation\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pansharpening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
